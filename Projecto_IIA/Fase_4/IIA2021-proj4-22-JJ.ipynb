{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Projeto nº 4 - Aprendizagem Automática\n",
    "### Introdução à Inteligência Artificial edição 2020/21\n",
    "\n",
    "\n",
    "## Grupo: 22\n",
    "\n",
    "### Elementos do Grupo\n",
    "\n",
    "Nome: André Firmino\n",
    "\n",
    "Número: 44999\n",
    "\n",
    "Nome: Joao Janeiro\n",
    "\n",
    "Número: 52779\n",
    "\n",
    "Nome: Nuno Estalagem\n",
    "\n",
    "Número 52828"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "De modo a conseguir concretizar este projeto,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsAA import *\n",
    "import numpy as np\n",
    "from random import*\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree # árvore de decisão\n",
    "from sklearn.neighbors import KNeighborsClassifier # k-NN\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 1 - *Load* de Dados\n",
    "Nesta fase do nosso projeto, temos como intenção o *load* dos \n",
    "dados. Esta fase é muito importante, já que, a partir dos dados dele,\n",
    "vai ser gerada, numa fase posterior, uma árvore de decisão, que nos auxiliará na extrapolação e previsão\n",
    "do melhor modelo possível, a ser aplicado no 'test.csv'. Como sugerido pelo enunciado, e tendo em vista o *load* de dados, recorremos à função *load_data* do módulo utilsAA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,target,feature_names,target_names=load_data('airline.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 2 - Processamento dos Dados\n",
    "Nesta fase do nosso projeto, verificámos se os dados de que fizemos *load* estão prontos a serem usados pelos algoritmos. \n",
    "Para que tal seja possível, temos de ter em atenção que os atributos do *airline.csv* são categóricos e, deste modo, necessitam de ser codificados, através do método *encode_feature*. Uma vez que o client_id é irrelevante, podemos remover a primeira coluna dos dados e do vector com o nome dos atributos. Finalmente, recorremos à função one_hot_encode_feature, que recebe os dados completos (*data*), o número da coluna que se pretende codificar(4) e o vector com o nome dos atributos (*feature_names*), tem como resultado, apagar essa coluna e adicionar no fim dos dados o número de colunas correspondentes ao número de categorias existentes nesse atributo categórico. A partir deste momento, todos os atributos são numéricos e podemos criar um modelo com árvores de decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = feature_names[1:]\n",
    "data = data[:,1:]\n",
    "data[:,0]=encode_feature(data[:,0])\n",
    "data[:,1]=encode_feature(data[:,1])\n",
    "data[:,3]=encode_feature(data[:,3])\n",
    "data, feature_names = one_hot_encode_feature(data, 4, feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 3 - Procura do Melhor Modelo\n",
    "Na fase 3, experimentámos os algoritmos das árvores de decisão e k vizinhos mais próximos, variando os respetivos parâmetros. A escolha do melhor modelo a aplicar no conjunto de teste fornecido foi feita, tendo em conta um algoritmo de *splitting*, para cada tipo de algoritmo (árvores de decisão e k vizinhos mais próximos). No contexto da aprendizagem automática, o *splitting* serve para aferir a qualidade do modelo de aprendizagem, dividindo os dados que temos em duas \"classes\": uma de treino e outra de teste. Uma das partes (treino) é usada para desenvolver um modelo preditivo, enquanto que outra (teste) é usada para avaliar desempenho do algoritmo. No código abaixo, está presente a forma de implementação dos algoritmos referidos acima, sendo que a ideia chave é calcular/averiguar quais são os melhores parâmetros a usar na árvore de decisão ou no k vizinhos mais próximos, conforme o que pretendermos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A maior percentagem eh 0.9061771561771561 e utilizamos valor: 13 6\n",
      "CV accuracy:\n",
      "\t0.8205128205128205\n",
      "\t0.9487179487179487\n",
      "\t0.9230769230769231\n",
      "\t0.9358974358974359\n",
      "\t0.9102564102564102\n",
      "\t0.9102564102564102\n",
      "\t0.9102564102564102\n",
      "\t0.8717948717948718\n",
      "\t0.8571428571428571\n",
      "\t0.961038961038961\n",
      "Average CV accuracy: 0.905 +/- 0.041\n",
      "A maior percentagem eh 0.6774225774225775 e utilizamos valor: 30\n",
      "CV accuracy:\n",
      "\t0.6538461538461539\n",
      "\t0.6282051282051282\n",
      "\t0.6666666666666666\n",
      "\t0.7051282051282052\n",
      "\t0.6794871794871795\n",
      "\t0.7564102564102564\n",
      "\t0.6282051282051282\n",
      "\t0.6666666666666666\n",
      "\t0.6753246753246753\n",
      "\t0.7142857142857143\n",
      "Average CV accuracy: 0.677 +/- 0.037\n"
     ]
    }
   ],
   "source": [
    "def best_splitter_dec_tree():\n",
    "    max_maior=0\n",
    "    value=0\n",
    "    value2=0\n",
    "    for x in range(21):\n",
    "        for y in range(21):\n",
    "            dtc = DecisionTreeClassifier(criterion='entropy',min_samples_split=x, max_depth=y)\n",
    "            scores = cross_val_score(dtc,\n",
    "                             X=data,\n",
    "                             y=target,\n",
    "                             cv=10,\n",
    "                             n_jobs=-1\n",
    "                            )\n",
    "            if np.mean(scores)>max_maior:\n",
    "                max_maior=np.mean(scores)\n",
    "                value=x\n",
    "                value2=y\n",
    "    print(\"A maior percentagem eh \" + str(max_maior)+ \" e utilizamos valor: \" + str(value) + \" \" +str(value2));\n",
    "    return(value,value2)\n",
    "\n",
    "valores=best_splitter_dec_tree()\n",
    "dtc = DecisionTreeClassifier(criterion='entropy',min_samples_split=valores[0],max_depth=valores[1])\n",
    "scores = cross_val_score(dtc,\n",
    "                         X=data,\n",
    "                         y=target,\n",
    "                         cv=10,\n",
    "                         n_jobs=-1\n",
    "                        )\n",
    "print('CV accuracy:', *scores, sep='\\n\\t')\n",
    "print('Average CV accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def best_splitter_neighbors():\n",
    "    max_maior=0\n",
    "    neighbors=0\n",
    "    for x in range(31):\n",
    "        dtc = KNeighborsClassifier(n_neighbors=x)\n",
    "        scores = cross_val_score(dtc,\n",
    "                             X=data,\n",
    "                             y=target,\n",
    "                             cv=10,\n",
    "                             n_jobs=-1\n",
    "                            )\n",
    "        if np.mean(scores)>max_maior:\n",
    "            max_maior=np.mean(scores)\n",
    "            neighbors=x\n",
    "    print(\"A maior percentagem eh \" + str(max_maior)+ \" e utilizamos valor: \" +str(neighbors));\n",
    "    return neighbors\n",
    "neighbors=best_splitter_neighbors()\n",
    "ctc =  KNeighborsClassifier(n_neighbors=neighbors)\n",
    "scores = cross_val_score(ctc,\n",
    "                         X=data,\n",
    "                         y=target,\n",
    "                         cv=10,\n",
    "                         n_jobs=-1\n",
    "                        )\n",
    "print('CV accuracy:', *scores, sep='\\n\\t')\n",
    "print('Average CV accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 4 - Gravação das Previsões\n",
    "Após a escolha do melhor modelo,calculado na alínea anterior, fizemos load dos dados de teste com a mesma função *load_data*, mas usando o argumento *testdata=True*, o que nos permite ler os dados sem a coluna das classes (que não irá existir neste conjunto de dados). De seguida, fazemos *fit* à árvore que é calculada na alínea número 3, gerando uma árvore de decisão. Para esta árvore, são chamados os valores de *test.csv*, prevendo, demonstrado na linha que diz *var = dtc.predict(data_test)*. E tendo em conta a árvore que fizemos a partir dos dados na 3º passo, verificamos se se consegue prever os resultados do *teste.csv*. Depois de fazer as previsões com o modelo escolhido, usámos a função *save_data* para gravar as nossas previsões para o conjunto de teste, gerando um ficheiro CSV com o nome *IIA2021-proj4-22.csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test, features_names_test = load_data(\"test.csv\",testdata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_names_test =  features_names_test[1:]\n",
    "data_test = data_test[:,1:]\n",
    "data_test[:,0]=encode_feature(data_test[:,0])\n",
    "data_test[:,1]=encode_feature(data_test[:,1])\n",
    "data_test[:,3]=encode_feature(data_test[:,3])\n",
    "data_test, features_names_test = one_hot_encode_feature(data_test, 4, features_names_test)\n",
    "dtc = DecisionTreeClassifier(criterion='entropy',min_samples_split=valores[0],max_depth=valores[1])\n",
    "dtc.fit(data,target)\n",
    "var=dtc.predict(data_test)\n",
    "\"\"\"\n",
    "plt.figure(figsize=[14,10])\n",
    "plot_tree(dtc,\n",
    "          feature_names=feature_names,\n",
    "          class_names=target,\n",
    "          filled=True, rounded=True)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "save_data('IIA2021-proj4-22.csv',var)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
